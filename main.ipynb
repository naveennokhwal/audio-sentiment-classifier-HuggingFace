{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Learning\\Machine-Learning\\Deep_Learning_WorkSpace\\base_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "from src.models import Wav2Vec2ForSpeechClassification, HubertForSpeechClassification\n",
    "from transformers import AutoConfig, Wav2Vec2FeatureExtractor\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at m3hrdadfi/hubert-base-persian-speech-emotion-recognition were not used when initializing HubertForSpeechClassification: ['hubert.encoder.pos_conv_embed.conv.weight_g', 'hubert.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing HubertForSpeechClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertForSpeechClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HubertForSpeechClassification were not initialized from the model checkpoint at m3hrdadfi/hubert-base-persian-speech-emotion-recognition and are newly initialized: ['hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name_or_path = \"m3hrdadfi/hubert-base-persian-speech-emotion-recognition\"\n",
    "config = AutoConfig.from_pretrained(model_name_or_path)\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name_or_path)\n",
    "sampling_rate = feature_extractor.sampling_rate\n",
    "model = HubertForSpeechClassification.from_pretrained(model_name_or_path).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sentiment mapping\n",
    "sentiment_mapping = {\n",
    "    \"S\": \"Sadness\",\n",
    "    \"A\": \"Anger\",\n",
    "    \"H\": \"Happiness\",\n",
    "    \"W\": \"Surprise\",\n",
    "    \"F\": \"Fear\",\n",
    "    \"N\": \"Neutral\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all .wav files in the folder\n",
    "def folder_to_list(folder_path):\n",
    "    audio_files = [f for f in os.listdir(folder_path) if f.endswith('.wav')]\n",
    "    # get entire path\n",
    "    audio_files = [os.path.join(folder_path, f) for f in audio_files]\n",
    "    return audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract sentiment from file name\n",
    "def extract_sentiment(file_name):\n",
    "    sentiment_code = file_name[-7]  # Assuming format always has sentiment at the third last character\n",
    "    \n",
    "    return sentiment_mapping.get(sentiment_code, \"Unknown\")\n",
    "\n",
    "# create a list of sentiments from file names\n",
    "def list_sentiments_from_files(folder_path):\n",
    "    # Get a list of all .wav files in the folder\n",
    "    audio_files = [f for f in os.listdir(folder_path) if f.endswith('.wav')]\n",
    "    \n",
    "    sentiments = []\n",
    "    for file in audio_files:\n",
    "        sentiment = extract_sentiment(file)\n",
    "        sentiments.append(sentiment)\n",
    "    \n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of paths of each sentiment\n",
    "def path_of_each_sentiment(folder_path):\n",
    "    audio_files = [f for f in os.listdir(folder_path) if f.endswith('.wav')]\n",
    "\n",
    "    Sadness = []\n",
    "    Anger = []\n",
    "    Happiness = []\n",
    "    Surprise = []\n",
    "    Fear = []\n",
    "    Neutral = []\n",
    "    \n",
    "    for file in audio_files:\n",
    "        sentiment_code = file[-7]\n",
    "        if sentiment_code == \"S\":\n",
    "            Sadness.append(os.path.join(folder_path, file))\n",
    "        elif sentiment_code == \"A\":\n",
    "            Anger.append(os.path.join(folder_path, file))\n",
    "        elif sentiment_code == \"H\":\n",
    "            Happiness.append(os.path.join(folder_path, file))\n",
    "        elif sentiment_code == \"W\":\n",
    "            Surprise.append(os.path.join(folder_path, file))\n",
    "        elif sentiment_code == \"F\":\n",
    "            Fear.append(os.path.join(folder_path, file))\n",
    "        elif sentiment_code == \"N\":\n",
    "            Neutral.append(os.path.join(folder_path, file))\n",
    "\n",
    "    return Sadness, Anger, Happiness, Surprise, Fear, Neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_file_to_array_fn(path, sampling_rate):\n",
    "    speech_array, _sampling_rate = torchaudio.load(path)\n",
    "    resampler = torchaudio.transforms.Resample(_sampling_rate, sampling_rate)\n",
    "    speech = resampler(speech_array).squeeze().numpy()\n",
    "    return speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(path, sampling_rate):\n",
    "    speech = speech_file_to_array_fn(path, sampling_rate)\n",
    "    inputs = feature_extractor(speech, sampling_rate=sampling_rate, return_tensors=\"pt\", padding=True)\n",
    "    inputs = {key: inputs[key].to(device) for key in inputs}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    \n",
    "    # Get softmax scores\n",
    "    scores = F.softmax(logits, dim=1).detach().cpu().numpy()[0]\n",
    "    \n",
    "    # Get the index of the highest score\n",
    "    max_index = scores.argmax()\n",
    "    \n",
    "    # Return the label with the highest score\n",
    "    sentiment = config.id2label[max_index]\n",
    "    \n",
    "    return sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(file_path, label):\n",
    "    predicted = []\n",
    "    for file in tqdm(file_path):\n",
    "        output = predict(file, sampling_rate)\n",
    "        if output == label:\n",
    "            predicted.append(1)\n",
    "        else:\n",
    "            predicted.append(0)\n",
    "    \n",
    "    return np.array(predicted), np.ones(len(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluation(actual_np, predicted_value):\n",
    "    predicted_np = np.array(predicted_value)\n",
    "\n",
    "    accuracy = accuracy_score(actual_np, predicted_np)\n",
    "    precision = precision_score(actual_np, predicted_np)\n",
    "    recall = recall_score(actual_np, predicted_np)\n",
    "    f1 = f1_score(actual_np, predicted_np)\n",
    "\n",
    "    matrix = {\n",
    "        \"accuracy\" : accuracy,\n",
    "        \"precision\" : precision,\n",
    "        \"recall\" : recall,\n",
    "        \"f1_score\" : f1\n",
    "    }\n",
    "\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the code for female audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing all your audio files\n",
    "folder_path = r\"C:\\Learning\\Machine-Learning\\Deep_Learning_WorkSpace\\files\\female\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists containg paths of sentiment \n",
    "actual_Sadness_paths, actual_Anger_paths, actual_Happiness_paths, actual_Surprise_paths, actual_Fear_paths, actual_Neutral_paths = path_of_each_sentiment(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 271/271 [02:54<00:00,  1.55it/s]\n",
      "100%|██████████| 455/455 [03:38<00:00,  2.09it/s]\n",
      "100%|██████████| 111/111 [00:55<00:00,  1.99it/s]\n",
      "100%|██████████| 120/120 [00:33<00:00,  3.61it/s]\n",
      "100%|██████████| 22/22 [00:09<00:00,  2.40it/s]\n",
      "100%|██████████| 284/284 [03:55<00:00,  1.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# list pf predicted values and actual values \n",
    "\n",
    "predict_Sadness, actual_Sadness = predict_sentiment(actual_Sadness_paths, \"Sadness\")\n",
    "predict_Anger, actual_Anger_value = predict_sentiment(actual_Anger_paths, \"Anger\")\n",
    "predict_Happiness, actual_Happiness = predict_sentiment(actual_Happiness_paths, \"Happiness\")\n",
    "predict_Surprise, actual_Surprise = predict_sentiment(actual_Surprise_paths, \"Surprise\")\n",
    "predict_Fear, actual_Fear = predict_sentiment(actual_Fear_paths, \"Fear\")\n",
    "predict_Neutral, actual_Neutral = predict_sentiment(actual_Neutral_paths, \"Neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation\n",
    "\n",
    "matrix_Sadness = evaluation(predict_Sadness, actual_Sadness)\n",
    "matrix_Anger = evaluation(predict_Anger, actual_Anger_value)\n",
    "matrix_Hapiness = evaluation(predict_Happiness, actual_Happiness)\n",
    "matrix_Surprise = evaluation(predict_Surprise, actual_Surprise)\n",
    "matrix_Fear = evaluation(predict_Fear, actual_Fear)\n",
    "matrix_Neutral = evaluation(predict_Neutral, actual_Neutral)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    Emotions   | precision | recall | f1-score | accuracy     |\n",
      "|:-------------:|:---------:|:------:|:--------:|:------------:|\n",
      "|   Anger       |   0.98    |   1.0  |   0.99   |     0.98     |\n",
      "|   Fear        |   0.59    |   1.0  |   0.74   |     0.59     |\n",
      "|   Hapiness    |   0.94    |   1.0  |   0.97   |     0.94     |\n",
      "|   Neutral     |   0.99    |   1.0  |   1.0    |     0.99     |\n",
      "|   Sadness     |   0.85    |   1.0  |   0.92   |     0.85     |\n",
      "|   Surprise    |   0.87    |   1.0  |   0.93   |     0.87     |\n"
     ]
    }
   ],
   "source": [
    "# get the results\n",
    "print(\"|    Emotions   | precision | recall | f1-score | accuracy     |\")\n",
    "print(\"|:-------------:|:---------:|:------:|:--------:|:------------:|\")\n",
    "print(f\"|   Anger       |   {round(matrix_Anger['precision']    ,2)}    |   {matrix_Anger['recall']     }  |   {round(matrix_Anger['f1_score']   ,2) }   |     {round(matrix_Anger['accuracy']      ,2)}     |\")\n",
    "print(f\"|   Fear        |   {round(matrix_Fear['precision']     ,2)}    |   {matrix_Fear['recall']      }  |   {round(matrix_Fear['f1_score']    ,2) }   |     {round(matrix_Fear['accuracy']       ,2)}     |\")\n",
    "print(f\"|   Hapiness    |   {round(matrix_Hapiness['precision'] ,2)}    |   {matrix_Hapiness['recall']  }  |   {round(matrix_Hapiness['f1_score'],2) }   |     {round(matrix_Hapiness['accuracy']   ,2)}     |\")\n",
    "print(f\"|   Neutral     |   {round(matrix_Neutral['precision']  ,2)}    |   {matrix_Neutral['recall']   }  |   {round(matrix_Neutral['f1_score'] ,2) }    |     {round(matrix_Neutral['accuracy']    ,2)}     |\")\n",
    "print(f\"|   Sadness     |   {round(matrix_Sadness['precision']  ,2)}    |   {matrix_Sadness['recall']   }  |   {round(matrix_Sadness['f1_score'] ,2) }   |     {round(matrix_Sadness['accuracy']    ,2)}     |\")\n",
    "print(f\"|   Surprise    |   {round(matrix_Surprise['precision'] ,2)}    |   {matrix_Surprise['recall']  }  |   {round(matrix_Surprise['f1_score'],2) }   |     {round(matrix_Surprise['accuracy']   ,2)}     |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run the code for male audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing all your audio files\n",
    "folder_path_male = r\"C:\\Learning\\Machine-Learning\\Deep_Learning_WorkSpace\\files\\male\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists containg paths of sentiment \n",
    "actual_Sadness_paths, actual_Anger_paths, actual_Happiness_paths, actual_Surprise_paths, actual_Fear_paths, actual_Neutral_paths = path_of_each_sentiment(folder_path_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 178/178 [02:05<00:00,  1.42it/s]\n",
      "100%|██████████| 604/604 [05:18<00:00,  1.89it/s]\n",
      "100%|██████████| 90/90 [00:47<00:00,  1.90it/s]\n",
      "100%|██████████| 105/105 [00:29<00:00,  3.59it/s]\n",
      "100%|██████████| 16/16 [00:07<00:00,  2.09it/s]\n",
      "100%|██████████| 744/744 [07:23<00:00,  1.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# list pf predicted values and actual values \n",
    "\n",
    "predict_Sadness, actual_Sadness = predict_sentiment(actual_Sadness_paths, \"Sadness\")\n",
    "predict_Anger, actual_Anger_value = predict_sentiment(actual_Anger_paths, \"Anger\")\n",
    "predict_Happiness, actual_Happiness = predict_sentiment(actual_Happiness_paths, \"Happiness\")\n",
    "predict_Surprise, actual_Surprise = predict_sentiment(actual_Surprise_paths, \"Surprise\")\n",
    "predict_Fear, actual_Fear = predict_sentiment(actual_Fear_paths, \"Fear\")\n",
    "predict_Neutral, actual_Neutral = predict_sentiment(actual_Neutral_paths, \"Neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation\n",
    "\n",
    "matrix_Sadness = evaluation(predict_Sadness, actual_Sadness)\n",
    "matrix_Anger = evaluation(predict_Anger, actual_Anger_value)\n",
    "matrix_Hapiness = evaluation(predict_Happiness, actual_Happiness)\n",
    "matrix_Surprise = evaluation(predict_Surprise, actual_Surprise)\n",
    "matrix_Fear = evaluation(predict_Fear, actual_Fear)\n",
    "matrix_Neutral = evaluation(predict_Neutral, actual_Neutral)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    Emotions   | precision | recall | f1-score | accuracy     |\n",
      "|:-------------:|:---------:|:------:|:--------:|:------------:|\n",
      "|   Anger       |   0.97    |   1.0  |   0.99   |     0.97     |\n",
      "|   Fear        |   0.69    |   1.0  |   0.81   |     0.69     |\n",
      "|   Hapiness    |   0.96    |   1.0  |   0.98   |     0.96     |\n",
      "|   Neutral     |   0.99    |   1.0  |   0.99   |     0.99     |\n",
      "|   Sadness     |   0.78    |   1.0  |   0.88   |     0.78     |\n",
      "|   Surprise    |   0.79    |   1.0  |   0.88   |     0.79     |\n"
     ]
    }
   ],
   "source": [
    "# get the results\n",
    "print(\"|    Emotions   | precision | recall | f1-score | accuracy     |\")\n",
    "print(\"|:-------------:|:---------:|:------:|:--------:|:------------:|\")\n",
    "print(f\"|   Anger       |   {round(matrix_Anger['precision']    ,2)}    |   {matrix_Anger['recall']     }  |   {round(matrix_Anger['f1_score']   ,2) }   |     {round(matrix_Anger['accuracy']      ,2)}     |\")\n",
    "print(f\"|   Fear        |   {round(matrix_Fear['precision']     ,2)}    |   {matrix_Fear['recall']      }  |   {round(matrix_Fear['f1_score']    ,2) }   |     {round(matrix_Fear['accuracy']       ,2)}     |\")\n",
    "print(f\"|   Hapiness    |   {round(matrix_Hapiness['precision'] ,2)}    |   {matrix_Hapiness['recall']  }  |   {round(matrix_Hapiness['f1_score'],2) }   |     {round(matrix_Hapiness['accuracy']   ,2)}     |\")\n",
    "print(f\"|   Neutral     |   {round(matrix_Neutral['precision']  ,2)}    |   {matrix_Neutral['recall']   }  |   {round(matrix_Neutral['f1_score'] ,2) }   |     {round(matrix_Neutral['accuracy']    ,2)}     |\")\n",
    "print(f\"|   Sadness     |   {round(matrix_Sadness['precision']  ,2)}    |   {matrix_Sadness['recall']   }  |   {round(matrix_Sadness['f1_score'] ,2) }   |     {round(matrix_Sadness['accuracy']    ,2)}     |\")\n",
    "print(f\"|   Surprise    |   {round(matrix_Surprise['precision'] ,2)}    |   {matrix_Surprise['recall']  }  |   {round(matrix_Surprise['f1_score'],2) }   |     {round(matrix_Surprise['accuracy']   ,2)}     |\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
