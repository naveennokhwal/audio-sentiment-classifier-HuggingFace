{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Learning\\Machine-Learning\\Deep_Learning_WorkSpace\\base_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "from src.models import Wav2Vec2ForSpeechClassification, HubertForSpeechClassification\n",
    "from transformers import AutoConfig, Wav2Vec2FeatureExtractor\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at m3hrdadfi/hubert-base-persian-speech-emotion-recognition were not used when initializing HubertForSpeechClassification: ['hubert.encoder.pos_conv_embed.conv.weight_g', 'hubert.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing HubertForSpeechClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertForSpeechClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HubertForSpeechClassification were not initialized from the model checkpoint at m3hrdadfi/hubert-base-persian-speech-emotion-recognition and are newly initialized: ['hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name_or_path = \"m3hrdadfi/hubert-base-persian-speech-emotion-recognition\"\n",
    "config = AutoConfig.from_pretrained(model_name_or_path)\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name_or_path)\n",
    "sampling_rate = feature_extractor.sampling_rate\n",
    "model = HubertForSpeechClassification.from_pretrained(model_name_or_path).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
    "sentiment_mapping = {\n",
    "    \"1\" : \"Neutral\",\n",
    "    \"3\" : \"Happiness\",\n",
    "    \"4\" : \"Sadness\",\n",
    "    \"5\" : \"Anger\",\n",
    "    \"6\" : \"Fear\",\n",
    "    \"8\" : \"Surprise\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(folder_path):\n",
    "    Sadness = []\n",
    "    Anger = []\n",
    "    Happiness = []\n",
    "    Surprise = []\n",
    "    Fear = []\n",
    "    Neutral = []\n",
    "\n",
    "    for path in folder_path:\n",
    "        audio_files = [f for f in os.listdir(path) if f.endswith('.wav')]\n",
    "\n",
    "        for file in audio_files:\n",
    "            sentiment_code = file[7]\n",
    "            if sentiment_code == \"4\":\n",
    "                Sadness.append(os.path.join(path, file))\n",
    "            elif sentiment_code == \"5\":\n",
    "                Anger.append(os.path.join(path, file))\n",
    "            elif sentiment_code == \"3\":\n",
    "                Happiness.append(os.path.join(path, file))\n",
    "            elif sentiment_code == \"8\":\n",
    "                Surprise.append(os.path.join(path, file))\n",
    "            elif sentiment_code == \"6\":\n",
    "                Fear.append(os.path.join(path, file))\n",
    "            elif sentiment_code == \"1\":\n",
    "                # print(os.path.join(path, file))\n",
    "                Neutral.append(os.path.join(path, file))\n",
    "    return Sadness, Anger, Happiness, Surprise, Fear, Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of paths of each sentiment\n",
    "def path_of_each_sentiment(folder_path):\n",
    "    audio_files = [f for f in os.listdir(folder_path) if f.endswith('.wav')]\n",
    "\n",
    "    Sadness = []\n",
    "    Anger = []\n",
    "    Happiness = []\n",
    "    Surprise = []\n",
    "    Fear = []\n",
    "    Neutral = []\n",
    "    \n",
    "    for file in audio_files:\n",
    "        sentiment_code = file[7]\n",
    "        if sentiment_code == \"4\":\n",
    "            Sadness.append(os.path.join(folder_path, file))\n",
    "        elif sentiment_code == \"5\":\n",
    "            Anger.append(os.path.join(folder_path, file))\n",
    "        elif sentiment_code == \"3\":\n",
    "            Happiness.append(os.path.join(folder_path, file))\n",
    "        elif sentiment_code == \"8\":\n",
    "            Surprise.append(os.path.join(folder_path, file))\n",
    "        elif sentiment_code == \"6\":\n",
    "            Fear.append(os.path.join(folder_path, file))\n",
    "        elif sentiment_code == \"1\":\n",
    "            Neutral.append(os.path.join(folder_path, file))\n",
    "\n",
    "    return Sadness, Anger, Happiness, Surprise, Fear, Neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_file_to_array_fn(path, sampling_rate):\n",
    "    speech_array, _sampling_rate = torchaudio.load(path)\n",
    "    resampler = torchaudio.transforms.Resample(_sampling_rate, sampling_rate)\n",
    "    speech = resampler(speech_array).squeeze().numpy()\n",
    "    return speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(path, sampling_rate):\n",
    "    speech = speech_file_to_array_fn(path, sampling_rate)\n",
    "    inputs = feature_extractor(speech, sampling_rate=sampling_rate, return_tensors=\"pt\", padding=True)\n",
    "    inputs = {key: inputs[key].to(device) for key in inputs}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    \n",
    "    # Get softmax scores\n",
    "    scores = F.softmax(logits, dim=1).detach().cpu().numpy()[0]\n",
    "    \n",
    "    # Get the index of the highest score\n",
    "    max_index = scores.argmax()\n",
    "    \n",
    "    # Return the label with the highest score\n",
    "    sentiment = config.id2label[max_index]\n",
    "    \n",
    "    return sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(file_path, label):\n",
    "    predicted = []\n",
    "    for file in tqdm(file_path):\n",
    "        output = predict(file, sampling_rate)\n",
    "        if output == label:\n",
    "            predicted.append(1)\n",
    "        else:\n",
    "            predicted.append(0)\n",
    "    \n",
    "    return np.array(predicted), np.ones(len(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluation(actual_np, predicted_value):\n",
    "    predicted_np = np.array(predicted_value)\n",
    "\n",
    "    accuracy = accuracy_score(actual_np, predicted_np)\n",
    "    precision = precision_score(actual_np, predicted_np)\n",
    "    recall = recall_score(actual_np, predicted_np)\n",
    "    f1 = f1_score(actual_np, predicted_np)\n",
    "\n",
    "    matrix = {\n",
    "        \"accuracy\" : accuracy,\n",
    "        \"precision\" : precision,\n",
    "        \"recall\" : recall,\n",
    "        \"f1_score\" : f1\n",
    "    }\n",
    "\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = r\"C:\\Learning\\Machine-Learning\\Deep_Learning_WorkSpace\\files\\RAVDESS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all folders (subdirectories) within the main folder\n",
    "folders_path = [os.path.join(main_folder, folder) for folder in os.listdir(main_folder) if os.path.isdir(os.path.join(main_folder, folder))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_Sadness_paths, actual_Anger_paths, actual_Happiness_paths, actual_Surprise_paths, actual_Fear_paths, actual_Neutral_paths = create_dataset(folders_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [01:30<00:00,  2.11it/s]\n",
      "100%|██████████| 192/192 [01:48<00:00,  1.78it/s]\n",
      "100%|██████████| 192/192 [01:34<00:00,  2.04it/s]\n",
      "100%|██████████| 192/192 [01:35<00:00,  2.02it/s]\n",
      "100%|██████████| 192/192 [01:35<00:00,  2.01it/s]\n",
      "100%|██████████| 96/96 [00:47<00:00,  2.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# list pf predicted values and actual values \n",
    "\n",
    "predict_Sadness, actual_Sadness = predict_sentiment(actual_Sadness_paths, \"Sadness\")\n",
    "predict_Anger, actual_Anger_value = predict_sentiment(actual_Anger_paths, \"Anger\")\n",
    "predict_Happiness, actual_Happiness = predict_sentiment(actual_Happiness_paths, \"Happiness\")\n",
    "predict_Surprise, actual_Surprise = predict_sentiment(actual_Surprise_paths, \"Surprise\")\n",
    "predict_Fear, actual_Fear = predict_sentiment(actual_Fear_paths, \"Fear\")\n",
    "predict_Neutral, actual_Neutral = predict_sentiment(actual_Neutral_paths, \"Neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation\n",
    "\n",
    "matrix_Sadness = evaluation(predict_Sadness, actual_Sadness)\n",
    "matrix_Anger = evaluation(predict_Anger, actual_Anger_value)\n",
    "matrix_Hapiness = evaluation(predict_Happiness, actual_Happiness)\n",
    "matrix_Surprise = evaluation(predict_Surprise, actual_Surprise)\n",
    "matrix_Fear = evaluation(predict_Fear, actual_Fear)\n",
    "matrix_Neutral = evaluation(predict_Neutral, actual_Neutral)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    Emotions   | precision | recall | f1-score | accuracy     |\n",
      "|:-------------:|:---------:|:------:|:--------:|:------------:|\n",
      "|   Anger       |   0.92    |   1.0  |   0.96   |     0.92     |\n",
      "|   Fear        |   0.02    |   1.0  |   0.04   |     0.02     |\n",
      "|   Hapiness    |   0.15    |   1.0  |   0.26   |     0.15     |\n",
      "|   Neutral     |   0.81    |   1.0  |   0.9    |     0.81     |\n",
      "|   Sadness     |   0.64    |   1.0  |   0.78   |     0.64     |\n",
      "|   Surprise    |   0.18    |   1.0  |   0.31   |     0.18     |\n"
     ]
    }
   ],
   "source": [
    "# get the results\n",
    "print(\"|    Emotions   | precision | recall | f1-score | accuracy     |\")\n",
    "print(\"|:-------------:|:---------:|:------:|:--------:|:------------:|\")\n",
    "print(f\"|   Anger       |   {round(matrix_Anger['precision']    ,2)}    |   {matrix_Anger['recall']     }  |   {round(matrix_Anger['f1_score']   ,2) }   |     {round(matrix_Anger['accuracy']      ,2)}     |\")\n",
    "print(f\"|   Fear        |   {round(matrix_Fear['precision']     ,2)}    |   {matrix_Fear['recall']      }  |   {round(matrix_Fear['f1_score']    ,2) }   |     {round(matrix_Fear['accuracy']       ,2)}     |\")\n",
    "print(f\"|   Hapiness    |   {round(matrix_Hapiness['precision'] ,2)}    |   {matrix_Hapiness['recall']  }  |   {round(matrix_Hapiness['f1_score'],2) }   |     {round(matrix_Hapiness['accuracy']   ,2)}     |\")\n",
    "print(f\"|   Neutral     |   {round(matrix_Neutral['precision']  ,2)}    |   {matrix_Neutral['recall']   }  |   {round(matrix_Neutral['f1_score'] ,2) }    |     {round(matrix_Neutral['accuracy']    ,2)}     |\")\n",
    "print(f\"|   Sadness     |   {round(matrix_Sadness['precision']  ,2)}    |   {matrix_Sadness['recall']   }  |   {round(matrix_Sadness['f1_score'] ,2) }   |     {round(matrix_Sadness['accuracy']    ,2)}     |\")\n",
    "print(f\"|   Surprise    |   {round(matrix_Surprise['precision'] ,2)}    |   {matrix_Surprise['recall']  }  |   {round(matrix_Surprise['f1_score'],2) }   |     {round(matrix_Surprise['accuracy']   ,2)}     |\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
